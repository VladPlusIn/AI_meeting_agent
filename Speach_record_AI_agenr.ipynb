{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file 'config.json' updated with the API key.\n",
      "Starting real-time speech recognition. Press Ctrl+C to stop.\n",
      "Loading Whisper model...\n",
      "Processing audio...\n",
      "Recognized Text: You\n",
      "Processing audio...\n",
      "Recognized Text: you\n",
      "Processing audio...\n",
      "Recognized Text: You\n",
      "Processing audio...\n",
      "Recognized Text: you\n",
      "Processing audio...\n",
      "Recognized Text: You\n",
      "Processing audio...\n",
      "Recognized Text: between the machine, the dishwasher, and the person.\n",
      "Processing audio...\n",
      "Processing audio...\n",
      "Error processing audio: cannot reshape tensor of 0 elements into shape [1, 0, 12, -1] because the unspecified dimension size -1 can be any value and is ambiguous\n",
      "Processing audio...\n",
      "Processing audio...\n",
      "Recognized Text: I was just, I was also like, I think I was also like, you were washing dishes.\n",
      "Recognized Text: \n",
      "Recognized Text: It was a dishwasher. So you were like the time an adult. You were like the machine. You were washing dishes.\n",
      "Processing audio...\n",
      "Recognized Text: I had no friends in the restaurant, they were all older and...\n",
      "Processing audio...\n",
      "Recognized Text: And they were all really tough. I don't know, in America, when you...\n",
      "Stopping real-time speech recognition.\n",
      "Session log saved to transcription_log.json\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import whisper\n",
    "import noisereduce as nr  # noise reduction package\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from openai import OpenAI  # Import the OpenAI client class\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration File Handling\n",
    "# ---------------------------\n",
    "CONFIG_FILE = \"config.json\"\n",
    "\n",
    "def load_or_create_config():\n",
    "    \"\"\"\n",
    "    Loads the configuration from CONFIG_FILE.\n",
    "    If the file does not exist or the API key is missing,\n",
    "    asks the user for an API key, saves it, and returns the configuration.\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    if os.path.exists(CONFIG_FILE):\n",
    "        try:\n",
    "            with open(CONFIG_FILE, \"r\") as f:\n",
    "                config = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading config file: {e}\")\n",
    "    \n",
    "    # Check if the API key exists and is non-empty.\n",
    "    if not config.get(\"api_key\"):\n",
    "        api_key = input(\"Please enter your OpenAI API key: \").strip()\n",
    "        config[\"api_key\"] = api_key\n",
    "        try:\n",
    "            with open(CONFIG_FILE, \"w\") as f:\n",
    "                json.dump(config, f, indent=4)\n",
    "            print(f\"Config file '{CONFIG_FILE}' updated with the API key.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving config file: {e}\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "config = load_or_create_config()\n",
    "API_KEY = config.get(\"api_key\")\n",
    "\n",
    "# ---------------------------\n",
    "# Global variables for session data\n",
    "# ---------------------------\n",
    "session_transcriptions = []\n",
    "session_lock = threading.Lock()\n",
    "session_timestamp = datetime.now().isoformat()\n",
    "\n",
    "# ---------------------------\n",
    "# GPT‑4 Analysis Function\n",
    "# ---------------------------\n",
    "def analyze_conversation(transcriptions):\n",
    "    \"\"\"\n",
    "    Sends the entire transcription to GPT‑4 for analysis.\n",
    "    GPT‑4 returns a JSON object containing:\n",
    "      - meeting_title: A subject summarizing the conversation.\n",
    "      - summary: A bullet‑point summary of the conversation.\n",
    "      - discussed_tasks: A list of any tasks that were discussed.\n",
    "    \"\"\"\n",
    "    conversation_text = \"\\n\".join(transcriptions)\n",
    "    prompt = f\"\"\"\n",
    "You are an expert meeting analyst. Analyze the following meeting transcription and provide:\n",
    "1. A meeting title (subject) summarizing the conversation.\n",
    "2. A summary of the conversation in bullet points.\n",
    "3. Any tasks discussed during the conversation (if any).\n",
    "\n",
    "Format your answer as a JSON object with the following keys: \"meeting_title\", \"summary\", \"discussed_tasks\".\n",
    "\n",
    "Meeting transcription:\n",
    "\\\"\\\"\\\"{conversation_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    try:\n",
    "        # Initialize the client using the provided API key and base URL.\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=API_KEY,\n",
    "        )\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert meeting analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        analyzed_data = response.choices[0].message.content  # Using dot notation\n",
    "        return json.loads(analyzed_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing conversation: {e}\")\n",
    "        return {\"meeting_title\": \"Unknown\", \"summary\": [], \"discussed_tasks\": []}\n",
    "\n",
    "# ---------------------------\n",
    "# Logging Function\n",
    "# ---------------------------\n",
    "def log_session(session_timestamp, transcriptions, analysis, log_file=\"transcription_log.json\"):\n",
    "    \"\"\"\n",
    "    Save the session transcriptions and analysis to a JSON file.\n",
    "    If the file exists, append the new session record.\n",
    "    Otherwise, create a new log file.\n",
    "    The record contains: timestamp, meeting_title, raw_records, summary, discussed_tasks.\n",
    "    \"\"\"\n",
    "    record = {\n",
    "        \"timestamp\": session_timestamp,\n",
    "        \"meeting_title\": analysis.get(\"meeting_title\", \"Unknown\"),\n",
    "        \"raw_records\": transcriptions,\n",
    "        \"summary\": analysis.get(\"summary\", []),\n",
    "        \"discussed_tasks\": analysis.get(\"discussed_tasks\", [])\n",
    "    }\n",
    "    if os.path.exists(log_file):\n",
    "        try:\n",
    "            with open(log_file, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading log file, starting new log: {e}\")\n",
    "            data = []\n",
    "    else:\n",
    "        data = []\n",
    "\n",
    "    data.append(record)\n",
    "    \n",
    "    try:\n",
    "        with open(log_file, \"w\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        print(f\"Session log saved to {log_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving session log: {e}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Audio Processing Function\n",
    "# ---------------------------\n",
    "def process_audio_in_real_time(model, audio_frames, rate):\n",
    "    \"\"\"\n",
    "    Process a batch of audio frames: apply noise reduction, transcribe using Whisper,\n",
    "    and add the recognized text to the global session log.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Processing audio...\")\n",
    "        audio_array = np.frombuffer(b\"\".join(audio_frames), dtype=np.int16).astype(np.float32) / 32768.0\n",
    "        audio_denoised = nr.reduce_noise(y=audio_array, sr=rate)\n",
    "        result = model.transcribe(audio_denoised, fp16=False, language=\"en\")\n",
    "        recognized_text = result.get(\"text\", \"\").strip()\n",
    "        print(f\"Recognized Text: {recognized_text}\")\n",
    "        with session_lock:\n",
    "            session_transcriptions.append(recognized_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {e}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Real-Time Speech Recognition Function\n",
    "# ---------------------------\n",
    "def real_time_speech_recognition(chunk_size=1024, fmt=pyaudio.paInt16, channels=1, rate=16000):\n",
    "    \"\"\"\n",
    "    Continuously read audio from the microphone, process in 5-second batches,\n",
    "    and transcribe the speech using the Whisper model.\n",
    "    \"\"\"\n",
    "    print(\"Starting real-time speech recognition. Press Ctrl+C to stop.\")\n",
    "    audio_interface = pyaudio.PyAudio()\n",
    "    stream = audio_interface.open(format=fmt, channels=channels, rate=rate, input=True, frames_per_buffer=chunk_size)\n",
    "    audio_frames = []\n",
    "    print(\"Loading Whisper model...\")\n",
    "    model = whisper.load_model(\"small.en\")\n",
    "    try:\n",
    "        while True:\n",
    "            audio_data = stream.read(chunk_size, exception_on_overflow=False)\n",
    "            audio_frames.append(audio_data)\n",
    "            if len(audio_frames) >= int(rate / chunk_size * 5):  # Process every 5 seconds\n",
    "                thread = threading.Thread(\n",
    "                    target=process_audio_in_real_time,\n",
    "                    args=(model, audio_frames.copy(), rate)\n",
    "                )\n",
    "                thread.start()\n",
    "                audio_frames = []\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopping real-time speech recognition.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio_interface.terminate()\n",
    "\n",
    "# ---------------------------\n",
    "# Main Execution\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        real_time_speech_recognition()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to start speech recognition: {e}\")\n",
    "    finally:\n",
    "        with session_lock:\n",
    "            if session_transcriptions:\n",
    "                analysis = analyze_conversation(session_transcriptions)\n",
    "                log_session(session_timestamp, session_transcriptions, analysis)\n",
    "            else:\n",
    "                print(\"No transcriptions to log for this session.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
